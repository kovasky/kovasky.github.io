<!doctype html><html lang=en class=no-js><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta http-equiv=Accept-CH content="DPR, Viewport-Width, Width"><link rel=icon href=/fav.ico type=image/gif><link rel=apple-touch-icon href=/fav.png><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" media=print onload='this.media="all"'><noscript><link href="https://fonts.googleapis.com/css2?family=Alata&family=Lora:ital,wght@0,400;0,500;0,600;0,700;1,400;1,500;1,600;1,700&family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel=stylesheet></noscript><meta property="og:url" content="https://kovasky.me/blogs/ollama_vulkan_intel/"><meta property="og:site_name" content="Kovasky Buezo | Software Developer, Cybersecurity Enthusiast"><meta property="og:title" content="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs"><meta property="og:description" content="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2025-02-21T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-21T00:00:00+00:00"><meta property="article:tag" content="Ollama"><meta property="article:tag" content="Vulkan"><meta property="article:tag" content="Intel Arc"><meta property="article:tag" content="Ai"><meta name=twitter:card content="summary"><meta name=twitter:title content="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs"><meta name=twitter:description content="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs."><link rel=stylesheet href=/bootstrap-5/css/bootstrap.min.css media=all><link rel=stylesheet href=https://kovasky.me/css/style.min.49c3c43aeb3ee2c6261ca9977385e7c6d6093cd1b2b7b286b115a05a474ccf00.css integrity="sha256-ScPEOus+4sYmHKmXc4XnxtYJPNGyt7KGsRWgWkdMzwA="><script src=https://kovasky.me/js/scripts.min.63cd948a67068774b66f61214f37a2c262c9b06ccebe6305578f06347f1e536e.js integrity="sha256-Y82UimcGh3S2b2EhTzeiwmLJsGzOvmMFV48GNH8eU24="></script><script src=https://kovasky.me/lazyimg/lazysizes/lazysizes.min.js async></script><link rel=preload href=/blogs/ollama_vulkan_intel/images/ollama_service.webp as=image fetchpriority=high><style>:root{--text-color:#343a40;--text-secondary-color:#6c757d;--background-color:#eaedf0;--secondary-background-color:#64ffda1a;--primary-color:#007bff;--secondary-color:#f8f9fa;--text-color-dark:#e4e6eb;--text-secondary-color-dark:#b0b3b8;--background-color-dark:#18191a;--secondary-background-color-dark:#212529;--primary-color-dark:#ffffff;--secondary-color-dark:#212529}body{font-size:1rem;font-weight:400;line-height:1.5;text-align:left}html{background-color:var(--background-color)!important}body::-webkit-scrollbar{height:0;width:8px;background-color:var(--background-color)}::-webkit-scrollbar-track{border-radius:1rem}::-webkit-scrollbar-thumb{border-radius:1rem;background:#b0b0b0;outline:1px solid var(--background-color)}#search-content::-webkit-scrollbar{width:.5em;height:.1em;background-color:var(--background-color)}</style><meta name=description content="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs."><meta property="og:image" content="images/ollama_service.webp"><script defer src=/fontawesome-6/all-6.4.2.js></script><title>Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs</title></head><body class="light dark"><script>document.documentElement.className="js"</script><script>let localStorageValue=localStorage.getItem("pref-theme"),mediaQuery=window.matchMedia("(prefers-color-scheme: dark)").matches;switch(localStorageValue){case"dark":document.body.classList.add("dark");break;case"light":document.body.classList.remove("dark");break;default:mediaQuery&&document.body.classList.add("dark");break}</script><header id=profileHeader><nav class="pt-3 navbar navbar-expand-lg animate"><div class="container-fluid mx-xs-2 mx-sm-5 mx-md-5 mx-lg-5"><a class="navbar-brand primary-font text-wrap" href=/><img src=/fav.ico width=30 height=30 class="d-inline-block align-top" alt=favicon>
Kovasky Buezo</a><div><input id=search autocomplete=off class="form-control mr-sm-2 d-none d-md-block" placeholder='Ctrl + k to Search...' aria-label=Search oninput=searchOnChange(event)></div><button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarContent aria-controls=navbarContent aria-expanded=false aria-label="Toggle navigation"><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="24" data-view-component="true"><path fill-rule="evenodd" d="M1 2.75A.75.75.0 011.75 2h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 2.75zm0 5A.75.75.0 011.75 7h12.5a.75.75.0 110 1.5H1.75A.75.75.0 011 7.75zM1.75 12a.75.75.0 100 1.5h12.5a.75.75.0 100-1.5H1.75z"/></svg></button><div class="collapse navbar-collapse text-wrap primary-font" id=navbarContent><ul class="navbar-nav ms-auto text-center"><li class="nav-item navbar-text d-block d-md-none"><div class=nav-link><input id=search autocomplete=off class="form-control mr-sm-2" placeholder='Ctrl + k to Search...' aria-label=Search oninput=searchOnChange(event)></div></li><li class="nav-item navbar-text"><a class=nav-link href=/#about aria-label=about>About Me</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#experience aria-label=experience>Experience</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#achievements aria-label=achievements>Credentials</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#projects aria-label=projects>Projects</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#education aria-label=education>Education</a></li><li class="nav-item navbar-text"><a class=nav-link href=/#contact aria-label=contact>Contact</a></li><li class="nav-item navbar-text"><a class=nav-link href=/blogs title="Blog posts">Blog</a></li><li class="nav-item navbar-text"><a class=nav-link title="ðŸ‡¨ðŸ‡¦  English">ðŸ‡¨ðŸ‡¦ English</a></li></ul></div></div></nav></header><div id=content><section id=single><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-9"><div class=pr-lg-4><div class="title mb-5"><h1 class="text-center mb-4">Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs</h1><div class=text-center>Kovasky Buezo
<small>|</small>
Feb 21, 2025
<span id=readingTime>min read</span></div><div class=text-center><p>edited on: February 28, 2025</p></div></div><div class=featured-image><noscript><img src=https://kovasky.me/ollama_service-1024x.webp class="img-fluid mx-auto d-block" loading=lazy height=766 width=1024 srcset="https://kovasky.me/ollama_service-270x.webp 270w,
https://kovasky.me/ollama_service-420x.webp 420w,
https://kovasky.me/ollama_service-570x.webp 570w,
https://kovasky.me/ollama_service-720x.webp 720w,
https://kovasky.me/ollama_service-1024x.webp 1024w" alt="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs"></noscript><img src=https://kovasky.me/ollama_service-120x%20Gaussian.webp data-src=https://kovasky.me/ollama_service-1024x.webp class="img-fluid mx-auto d-block blur-up lazyload" height=766 width=1024 data-sizes=auto data-srcset="https://kovasky.me/ollama_service-270x.webp 270w,
https://kovasky.me/ollama_service-420x.webp 420w,
https://kovasky.me/ollama_service-570x.webp 570w,
https://kovasky.me/ollama_service-720x.webp 720w,
https://kovasky.me/ollama_service-1024x.webp 1024w" alt="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs"></div><article class="page-content p-2"><h2 id=intro>Intro</h2><p>I have an Intel Arc A380 in my Dell T440 server for Plex and remote gaming through Sunshine. I set up <a href=https://hoarder.app>Hoarder</a> and wanted a way to use the AI features without paying for OpenAI tokens. This proved extremely difficult, as none of the readily available solutions seemed to work.</p><p>This was until I tried LMStudio. LMStudio worked out of the box, but launching it in a headless manner on boot is not possible (at least for me), not to mention the incompatibility of its OpenAPI implementation with Hoarder. I later learned that LMStudio uses a vulkan backend, and went on a quest to find an ollama version with vulkan support.</p><p>Ollama does not currently support Vulkan and it looks like it won&rsquo;t any time soon, (read about that <a href=https://github.com/ollama/ollama/pull/5059#issuecomment-2629465081>here</a>) but there is an actively developed fork by <a href=https://github.com/whyvl>@Whyvl</a>, <a href=https://github.com/whyvl/ollama-vulkan>ollama-vulkan</a>.</p><p>Below are the steps needed to build and run ollama with a vulkan backend.</p><h2 id=pre-requisites>Pre-requisites</h2><p>I used an Ubuntu 24.04 (Noble Numbat) host, so your mileage may vary under different distros.</p><p>To install the required packages, issue the following commands:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo apt update
</span></span><span style=display:flex><span>sudo apt install git cmake wget libcap-dev golang-go </span></span></code></pre></div><p>To install the vulkan-sdk, you need to run:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | sudo tee /etc/apt/trusted.gpg.d/lunarg.asc
</span></span><span style=display:flex><span>sudo wget -qO /etc/apt/sources.list.d/lunarg-vulkan-noble.list http://packages.lunarg.com/vulkan/lunarg-vulkan-noble.list
</span></span><span style=display:flex><span>sudo apt update
</span></span><span style=display:flex><span>sudo apt install vulkan-sdk</span></span></code></pre></div><p>You also need this file: <a href=https://github.com/user-attachments/files/18783263/0002-fix-fix-vulkan-building.patch target=_blank>fix-vulkan-building.patch</a>. Save it somewhere easily accessible (like your downloads folder).</p><h2 id=setting-up-the-repo>Setting up the repo</h2><p>Next, you need to set up the repositories and apply the patch you downloaded. Use:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git clone -b vulkan https://github.com/whyvl/ollama-vulkan.git
</span></span><span style=display:flex><span>cd ollama-vulkan
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git remote add ollama_vanilla https://github.com/ollama/ollama.git
</span></span><span style=display:flex><span>git fetch ollama_vanilla --tags
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># the latest release as of now is 0.5.11</span>
</span></span><span style=display:flex><span>git checkout tags/v0.5.11 -b ollama_vanilla_stable
</span></span><span style=display:flex><span>git checkout vulkan
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git merge ollama_vanilla_stable --allow-unrelated-histories --no-edit
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>patch -p1 -N &lt; &lt;path to patch file&gt;</span></span></code></pre></div><h2 id=building-ollama>Building Ollama</h2><p>After downloading the repo and applying the patches, its time to build!</p><p>Run:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>make -f Makefile.sync clean sync
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># CPU libraries</span>
</span></span><span style=display:flex><span>cmake --preset CPU
</span></span><span style=display:flex><span>cmake --build --parallel --preset CPU
</span></span><span style=display:flex><span>cmake --install build --component CPU --strip
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Vulkan libraries</span>
</span></span><span style=display:flex><span>cmake --preset Vulkan
</span></span><span style=display:flex><span>cmake --build --parallel --preset Vulkan
</span></span><span style=display:flex><span>cmake --install build --component Vulkan --strip
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Binary</span>
</span></span><span style=display:flex><span>source scripts/env.sh <span style=color:#f92672>||</span> true
</span></span><span style=display:flex><span>mkdir -p dist/bin
</span></span><span style=display:flex><span>go build -trimpath -buildmode<span style=color:#f92672>=</span>pie -o dist/bin/ollama .</span></span></code></pre></div><p>Once the build is finished, run the server with:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>OLLAMA_HOST<span style=color:#f92672>=</span>0.0.0.0:11434 ./dist/bin/ollama serve</span></span></code></pre></div><p>If you get the error &ldquo;Please enable CAP_PERFMON or run as root to use Vulkan.&rdquo;, you have to run the binary as root.</p><h2 id=automated-script>Automated Script</h2><p>If you donâ€™t want to run all the steps manually, you can use this script:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>export CGO_ENABLED<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>export LDFLAGS<span style=color:#f92672>=</span>-s
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Pre-requisites</span>
</span></span><span style=display:flex><span>wget -qO- https://packages.lunarg.com/lunarg-signing-key-pub.asc | sudo tee /etc/apt/trusted.gpg.d/lunarg.asc
</span></span><span style=display:flex><span>sudo wget -qO /etc/apt/sources.list.d/lunarg-vulkan-noble.list http://packages.lunarg.com/vulkan/lunarg-vulkan-noble.list
</span></span><span style=display:flex><span>sudo apt update
</span></span><span style=display:flex><span>sudo apt install -y git vulkan-sdk cmake wget libcap-dev golang-go 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>mkdir -p /tmp/patches
</span></span><span style=display:flex><span>wget -O /tmp/patches/0002-fix-fix-vulkan-building.patch https://github.com/user-attachments/files/18783263/0002-fix-fix-vulkan-building.patch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Downloading repos and applying patches</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;Cloning and setting up ollama-vulkan repository...&#34;</span>
</span></span><span style=display:flex><span>REPO_DIR<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;/tmp/ollama-vulkan-git&#34;</span>
</span></span><span style=display:flex><span>rm -rf <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>REPO_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span> 2&gt;/dev/null <span style=color:#f92672>||</span> true
</span></span><span style=display:flex><span>git clone -b vulkan https://github.com/whyvl/ollama-vulkan.git <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>REPO_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>cd <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>REPO_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>git remote add ollama_vanilla https://github.com/ollama/ollama.git
</span></span><span style=display:flex><span>git fetch ollama_vanilla --tags
</span></span><span style=display:flex><span>git checkout tags/v0.5.11 -b ollama_vanilla_stable
</span></span><span style=display:flex><span>git checkout vulkan
</span></span><span style=display:flex><span>git merge ollama_vanilla_stable --allow-unrelated-histories --no-edit
</span></span><span style=display:flex><span>patch -p1 -N &lt; /tmp/patches/0002-fix-fix-vulkan-building.patch
</span></span><span style=display:flex><span>make -f Makefile.sync clean sync
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Building</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;Building CPU variant...&#34;</span>
</span></span><span style=display:flex><span>cmake --preset CPU
</span></span><span style=display:flex><span>cmake --build --parallel --preset CPU
</span></span><span style=display:flex><span>cmake --install build --component CPU --strip
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;Building Vulkan variant...&#34;</span>
</span></span><span style=display:flex><span>cmake --preset Vulkan
</span></span><span style=display:flex><span>cmake --build --parallel --preset Vulkan
</span></span><span style=display:flex><span>cmake --install build --component Vulkan --strip
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;Building final ollama binary...&#34;</span>
</span></span><span style=display:flex><span>cd <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>${</span>REPO_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>source scripts/env.sh <span style=color:#f92672>||</span> true
</span></span><span style=display:flex><span>mkdir -p dist/bin
</span></span><span style=display:flex><span>go build -trimpath -buildmode<span style=color:#f92672>=</span>pie -o dist/bin/ollama .
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Done!</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;Build completed.&#34;</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;CPU libraries are in:      </span><span style=color:#e6db74>${</span>REPO_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>/dist/lib/ollama&#34;</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;Vulkan libraries are in:   </span><span style=color:#e6db74>${</span>REPO_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>/dist/lib/ollama/vulkan&#34;</span>
</span></span><span style=display:flex><span>echo <span style=color:#e6db74>&#34;ollama binary is in:       </span><span style=color:#e6db74>${</span>REPO_DIR<span style=color:#e6db74>}</span><span style=color:#e6db74>/dist/bin/ollama&#34;</span></span></span></code></pre></div><h2 id=done>Done!</h2><p>You should now be able to load models using vulkan, leveraging your Intel GPU.</p><h2 id=resources>Resources</h2><p>Special thanks to <a href=https://github.com/McBane87>@McBane87</a> for a DockerFile that helped me build the project locally and to <a href=https://github.com/Dts0>@Dts0</a> for the patch.</p><ul><li><a href=https://github.com/whyvl/ollama-vulkan target=_blank>ollama-vulkan</a></li><li><a href=https://github.com/whyvl/ollama-vulkan/issues/7 target=_blank>ollama-vulkan/issues/7</a></li><li><a href=https://github.com/ollama/ollama target=_blank>ollama</a></li><li><a href=https://github.com/ollama/ollama/pull/5059 target=_blank>ollama/pull/5059</a></li></ul><hr><div id=load_comments style=text-align:center;display:block><button onclick=toggleComments()><i class="fa-solid fa-comments"></i> View Comments</button></div><h2 id=comments_header style=display:none>Comments</h2><div id=cusdis_thread data-host=https://cusdis.com data-app-id=fdd898fc-afd5-4280-9cb3-6dd7a1a05e17 data-page-id=https://kovasky.me/blogs/ollama_vulkan_intel/ data-page-url=https://kovasky.me/blogs/ollama_vulkan_intel/ data-page-title="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs" data-theme=dark style=min-height:50vh;display:none;resize:vertical;overflow:auto></div><div id=hide_comments style=text-align:center;display:none><br><button onclick=toggleComments()><i class="fa-solid fa-comments"></i> Hide Comments</button></div></article></div></div><div class="col-sm-12 col-md-12 col-lg-3"><div id=stickySideBar class=sticky-sidebar><aside class=toc><h5>Table Of Contents</h5><div class=toc-content><nav id=TableOfContents><ul><li><a href=#intro>Intro</a></li><li><a href=#pre-requisites>Pre-requisites</a></li><li><a href=#setting-up-the-repo>Setting up the repo</a></li><li><a href=#building-ollama>Building Ollama</a></li><li><a href=#automated-script>Automated Script</a></li><li><a href=#done>Done!</a></li><li><a href=#resources>Resources</a></li></ul></nav></div></aside><aside class=tags><h5>Tags</h5><ul class="tags-ul list-unstyled list-inline"><li class=list-inline-item><a href=/tags/ollama target=_blank>ollama</a></li><li class=list-inline-item><a href=/tags/vulkan target=_blank>vulkan</a></li><li class=list-inline-item><a href=/tags/intel-arc target=_blank>intel arc</a></li><li class=list-inline-item><a href=/tags/ai target=_blank>ai</a></li></ul></aside><aside class=social><h5>Social</h5><div class=social-content><ul class=list-inline><li class="list-inline-item text-center"><a target=_blank href="https://twitter.com/share?text=Build%20and%20run%20ollama%20with%20vulkan%20support%20to%20enable%20local%20inference%20on%20Intel%20Arc%20GPUs&url=https%3a%2f%2fkovasky.me%2fblogs%2follama_vulkan_intel%2f"><i class="fab fa-twitter"></i></a></li><li class="list-inline-item text-center"><a target=_blank href="https://api.whatsapp.com/send?text=Build%20and%20run%20ollama%20with%20vulkan%20support%20to%20enable%20local%20inference%20on%20Intel%20Arc%20GPUs: https%3a%2f%2fkovasky.me%2fblogs%2follama_vulkan_intel%2f"><i class="fab fa-whatsapp"></i></a></li><li class="list-inline-item text-center"><a target=_blank href='mailto:?subject=Build%20and%20run%20ollama%20with%20vulkan%20support%20to%20enable%20local%20inference%20on%20Intel%20Arc%20GPUs&amp;body=Check%20out%20this%20site https%3a%2f%2fkovasky.me%2fblogs%2follama_vulkan_intel%2f'><i class="fa fa-envelope"></i></a></li></ul></div></aside></div></div></div></div><button class="p-2 px-3" onclick=topFunction() id=topScroll>
<i class="fas fa-angle-up"></i></button></section><div class=progress><div id=scroll-progress-bar class=progress-bar role=progressbar aria-valuenow=0 aria-valuemin=0 aria-valuemax=100></div></div><script>var topScroll=document.getElementById("topScroll");window.onscroll=function(){scrollFunction()};function scrollFunction(){document.body.scrollTop>20||document.documentElement.scrollTop>20?topScroll.style.display="block":topScroll.style.display="none"}function topFunction(){document.body.scrollTop=0,document.documentElement.scrollTop=0}let stickySideBarElem=document.getElementById("stickySideBar"),stickyNavBar=!1;if(stickyNavBar){let e=document.getElementById("profileHeader"),t=e.offsetHeight+15;stickySideBarElem.style.top=t+"px"}else stickySideBarElem.style.top="50px"</script><script>function toggleComments(){var e,t,n,s,o=document.getElementById("cusdis_thread");o.style.display=o.style.display==="flex"?"none":"flex",t=document.getElementById("load_comments"),t.style.display=t.style.display==="block"?"none":"block",n=document.getElementById("comments_header"),n.style.display=n.style.display==="block"?"none":"block",s=document.getElementById("hide_comments"),s.style.display=s.style.display==="block"?"none":"block",e=document.getElementById("cusdis_script"),e===null&&(e=document.createElement("script"),e.src="https://cusdis.com/js/cusdis.es.js",e.async=!1,e.defer=!1,e.id="cusdis_script",document.body.appendChild(e))}</script></div><footer><div class="container py-3" id=recent-posts><div class="h3 text-center text-secondary py-3">Recent Posts</div><div class="row justify-content-center"><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class=card-header><a href=/blogs/pfsense_haproxy_authelia/><img loading=lazy src=https://kovasky.me/blogs/pfsense_haproxy_authelia/images/authelia_login.webp class=card-img-top alt="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs"></a></div><div class="card-body bg-transparent p-3 shadow-sm"><a href=/blogs/pfsense_haproxy_authelia/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="Configure HAProxy with Authelia on pfSense">Configure HAProxy with â€¦</h5></a><div class="card-text secondary-font"><p>Intro Some of my hosted services do not have OIDC support or any sort of authentication out of the box. Since I am already running an instance of Authelia, I decided to use it to secure those services. It was not as straight forward as I thought, specially using HAProxy on pfSense. There are a few â€¦</p></div></div><div class="mt-auto card-footer"><span class=float-start>Aug 18, 2025</span>
<a href=/blogs/pfsense_haproxy_authelia/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class=card-header><a href=/blogs/pfsense_fail2ban/><img loading=lazy src=https://kovasky.me/blogs/pfsense_fail2ban/images/pfsense_alias.webp class=card-img-top alt="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs"></a></div><div class="card-body bg-transparent p-3 shadow-sm"><a href=/blogs/pfsense_fail2ban/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="Connect Fail2Ban with pfSense">Connect Fail2Ban with â€¦</h5></a><div class="card-text secondary-font"><p>Intro Some of my self-hosted services don&rsquo;t play nicely with Cloudflare proxying. This has led me to use DNS and forgo Cloudflare&rsquo;s protection. Many of the guides out there require pfBlockerNG or the use of scripts that authenticate to pfSense via SSH. This guide will help you integrate â€¦</p></div></div><div class="mt-auto card-footer"><span class=float-start>Aug 3, 2025</span>
<a href=/blogs/pfsense_fail2ban/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div><div class="col-lg-4 col-md-6 pt-2"><div class="card h-100"><div class=card-header><a href=/blogs/rtx_5000_passthrough/><img loading=lazy src=https://kovasky.me/blogs/rtx_5000_passthrough/images/5060.webp class=card-img-top alt="Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs"></a></div><div class="card-body bg-transparent p-3 shadow-sm"><a href=/blogs/rtx_5000_passthrough/ class="primary-font card-title"><h5 class="card-title bg-transparent" title="How to passthrough an RTX 5000 series GPU to Proxmox">How to passthrough an RTX â€¦</h5></a><div class="card-text secondary-font"><p>Intro I recently acquired an RTX 5060 GPU and had to look at multiple sources in order to get passthrough working. This will outline all the steps I took in order to get it working on my Dell Poweredge T440 server.
Update At the time of the post edit, Proxmox 9 has been released. I have updated my â€¦</p></div></div><div class="mt-auto card-footer"><span class=float-start>Jul 20, 2025</span>
<a href=/blogs/rtx_5000_passthrough/ class="float-end btn btn-outline-info btn-sm">Read</a></div></div></div></div></div><div class="text-center pt-2"><span class=px-1><a href=https://github.com/kovasky aria-label=github><svg width="2.7em" height="2.7em" viewBox="0 0 1792 1792"><path d="M522 1352q-8 9-20-3-13-11-4-19 8-9 20 3 12 11 4 19zm-42-61q9 12 0 19-8 6-17-7t0-18q9-7 17 6zm-61-60q-5 7-13 2-10-5-7-12 3-5 13-2 10 5 7 12zm31 34q-6 7-16-3-9-11-2-16 6-6 16 3 9 11 2 16zm129 112q-4 12-19 6-17-4-13-15t19-7q16 5 13 16zm63 5q0 11-16 11-17 2-17-11 0-11 16-11 17-2 17 11zm58-10q2 10-14 14t-18-8 14-15q16-2 18 9zm964-956v960q0 119-84.5 203.5T1376 1664h-224q-16 0-24.5-1t-19.5-5-16-14.5-5-27.5v-239q0-97-52-142 57-6 102.5-18t94-39 81-66.5 53-105T1386 856q0-121-79-206 37-91-8-204-28-9-81 11t-92 44l-38 24q-93-26-192-26t-192 26q-16-11-42.5-27T578 459.5 492 446q-44 113-7 204-79 85-79 206 0 85 20.5 150t52.5 105 80.5 67 94 39 102.5 18q-40 36-49 103-21 10-45 15t-57 5-65.5-21.5T484 1274q-19-32-48.5-52t-49.5-24l-20-3q-21 0-29 4.5t-5 11.5 9 14 13 12l7 5q22 10 43.5 38t31.5 51l10 23q13 38 44 61.5t67 30 69.5 7 55.5-3.5l23-4q0 38 .5 103t.5 68q0 22-11 33.5t-22 13-33 1.5H416q-119 0-203.5-84.5T128 1376V416q0-119 84.5-203.5T416 128h960q119 0 203.5 84.5T1664 416z"/></svg>
</a></span><span class=px-1><a href=https://www.linkedin.com/in/kovaskybuezo/ aria-label=linkedin><svg width="2.4em" height="2.4em" fill="#fff" aria-label="LinkedIn" viewBox="0 0 512 512"><rect width="512" height="512" fill="#0077b5" rx="15%"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg></a></span></div><div class="container py-4"><div class="row justify-content-center"><div class="col-md-4 text-center"><div class=pb-2><a href=https://kovasky.me/ title="Kovasky Buezo | Software Developer, Cybersecurity Enthusiast"><img alt="Footer logo" src=/fav.ico height=40px width=40px></a></div>&copy; 2025 All rights reserved<div class=text-secondary>Made with
<span class=text-danger>&#10084;</span></div></div></div></div></footer><script src=/bootstrap-5/js/bootstrap.bundle.min.js></script><script>document.body.className.includes("light")&&(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))</script><script defer data-domain=kovasky.me src=https://plausible.agrajag.cloud/js/script.js></script><section id=search-content class=py-2><div class=container id=search-results></div></section></body></html>