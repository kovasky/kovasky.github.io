<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>vulkan on Kovasky Buezo | Software Developer, Cybersecurity Enthusiast</title><link>https://kovasky.me/tags/vulkan/</link><description>Recent content in vulkan on Kovasky Buezo | Software Developer, Cybersecurity Enthusiast</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 21 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://kovasky.me/tags/vulkan/index.xml" rel="self" type="application/rss+xml"/><item><title>Build and run ollama with vulkan support to enable local inference on Intel Arc GPUs</title><link>https://kovasky.me/blogs/ollama_vulkan_intel/</link><pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><guid>https://kovasky.me/blogs/ollama_vulkan_intel/</guid><description>Intro I have an Intel Arc A380 in my Dell T440 server for Plex and remote gaming through Sunshine. I set up Hoarder and wanted a way to use the AI features without paying for OpenAI tokens. This proved extremely difficult, as none of the readily available solutions seemed to work.
This was until I tried LMStudio. LMStudio worked out of the box, but launching it in a headless manner on boot is not possible (at least for me), not to mention the incompatibility of its OpenAPI implementation with Hoarder.</description></item></channel></rss>